{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, Conv2DTranspose\n",
        "from tensorflow.keras import Model"
      ],
      "metadata": {
        "id": "2GVQYz0BMBSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "Xim7XU6cQkx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"train path\"\n",
        "test_path = \"test path\""
      ],
      "metadata": {
        "id": "aTPot1fISA-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "L2uzHOurnEA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number of images\n",
        "n = len(os.listdir(train_path))"
      ],
      "metadata": {
        "id": "L_K3pyaJhIM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_directory = os.listdir(train_path)"
      ],
      "metadata": {
        "id": "wvXQ0SVuhl1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we will combine the masks (merge)"
      ],
      "metadata": {
        "id": "4bAaXeqqiEXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width = 128\n",
        "img_height = 128\n",
        "img_channels = 3"
      ],
      "metadata": {
        "id": "Q7Blf3HxiYIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.zeros((n,img_height, img_width, img_channels), dtype = np.unit8)\n",
        "y_train = np.zeros((n, img_height, img_width, 1), dtype = np.bool)"
      ],
      "metadata": {
        "id": "F83YHXjMihT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  #getting training images\n",
        "for i in tqdm(range(n)):\n",
        "  img_path = train_path + \"/\" + train_images_directory[i] + \"/images/\"\n",
        "  img_name = os.listdir(img_path)[0]\n",
        "  img = imread(img_path + \"/\" + img_name)[:,:,:,img_channels]\n",
        "  img = resize(img, (img_height, img_width), mode = \"constant\", preserve_range = True)\n",
        "\n",
        "  x_train[i] = img\n",
        "  mask_path = train_path + \"/\" + train_images_directory[i] + \"/masks/\"\n",
        "  mask_n = os.listdir(mask_path)\n",
        "  mask = np.zeros([img_height, img_width, 1], dtype = np.bool)\n",
        "\n",
        "  for j in range(len(mask_n)):\n",
        "    mask_img = imread(mask_path + \"/\" + mask_n[j])\n",
        "    mask_img = np.expand_dims(resize(mask_img, img_height, img_width),mode = \"constant\",preserve_range=True, axis = -1)\n",
        "    mask = np.maximum(mask, mask_img)\n",
        "\n",
        "  y_train[i] = mask\n",
        "\n",
        "#you wull now have 1 mask image for each image as we have comboned the mutiple mask images for one single img"
      ],
      "metadata": {
        "id": "ODHNOgogiHEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#looking at an image\n",
        "imshow(x_train[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G-r4JaARknD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mask of above img\n",
        "imshow(y_train[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J2_MME73o1zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#UNet Model\n",
        "\n",
        "# > segmentation consists of classification and localization\n",
        "\n",
        "inputs = Input((img_height, img_width, img_channels))\n",
        "x = tf.keras.layers.Lambda(lambda x : x/255)(inputs)\n",
        "\n",
        "#downsampling\n",
        "c1 = Conv2D(16,(3,3), activation = \"relu\", padding = \"same\")(x)\n",
        "c1 = Dropout(0.1)(c1) #adding from out side..not compulsory\n",
        "c1 = Conv2D(16,(3,3), activation = \"relu\", padding = \"same\")(c1)\n",
        "p1 = MaxPool2D((2,2))(c1)\n",
        "\n",
        "c2 = Conv2D(32,(3,3), activation = \"relu\", padding = \"same\")(p1)\n",
        "c2 = Dropout(0.1)(c2)\n",
        "c2 = Conv2D(32,(3,3), activation = \"relu\", padding = \"same\")(c2)\n",
        "p2 = MaxPool2D((2,2))(c2)\n",
        "\n",
        "c3 = Conv2D(64,(3,3), activation = \"relu\", padding = \"same\")(p2)\n",
        "c3 = Dropout(0.1)(c3)\n",
        "c3 = Conv2D(64,(3,3), activation = \"relu\", padding = \"same\")(c3)\n",
        "p3 = MaxPool2D((2,2))(c3)\n",
        "\n",
        "c4 = Conv2D(128,(3,3), activation = \"relu\", padding = \"same\")(p3)\n",
        "c4 = Dropout(0.1)(c4)\n",
        "c4 = Conv2D(128,(3,3), activation = \"relu\", padding = \"same\")(c4)\n",
        "p4 = MaxPool2D((2,2))(c4)\n",
        "\n",
        "c5 = Conv2D(256,(3,3), activation = \"relu\", padding = \"same\")(p4)\n",
        "c5 = Dropout(0.1)(c5)\n",
        "c5 = Conv2D(256,(3,3), activation = \"relu\", padding = \"same\")(c5)\n",
        "\n",
        "#upsampling\n",
        "u6 = Conv2DTranspose(128,(2,2), strides = (2,2), padding = \"same\")(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6,c4])\n",
        "c6 = Conv2D(128, (3,3), activation. = \"relu\", padding = \"same\")(u6)\n",
        "c6 = Dropout(0.2)(c6)\n",
        "c6 = Conv2D(128, (3,3), activation. = \"relu\", padding = \"same\")(c6)\n",
        "\n",
        "u7 = Conv2DTranspose(128,(2,2), strides = (2,2), padding = \"same\")(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7,c3])\n",
        "c7 = Conv2D(64, (3,3), activation. = \"relu\", padding = \"same\")(u7)\n",
        "c7 = Dropout(0.2)(c7)\n",
        "c7 = Conv2D(64, (3,3), activation. = \"relu\", padding = \"same\")(c7)\n",
        "\n",
        "u8 = Conv2DTranspose(32,(2,2), strides = (2,2), padding = \"same\")(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8,c2])\n",
        "c8 = Conv2D(32, (3,3), activation. = \"relu\", padding = \"same\")(u8)\n",
        "c8 = Dropout(0.2)(c8)\n",
        "c8 = Conv2D(32, (3,3), activation. = \"relu\", padding = \"same\")(c8)\n",
        "\n",
        "u9 = Conv2DTranspose(16,(2,2), strides = (2,2), padding = \"same\")(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9,c1])\n",
        "c9 = Conv2D(16, (3,3), activation. = \"relu\", padding = \"same\")(u9)\n",
        "c9 = Dropout(0.2)(c9)\n",
        "c9 = Conv2D(16, (3,3), activation. = \"relu\", padding = \"same\")(c9)\n",
        "\n",
        "outputs = Conv2D(1, (1,1), activation = \"sigmoid\")(c9)\n",
        "\n",
        "model = Model(inputs = [inputs], outputs = outputs)"
      ],
      "metadata": {
        "id": "DGMoT9pjpCPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "rqf5sAvmdth2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, to_file = \"model.png\", show_shapes = True)"
      ],
      "metadata": {
        "id": "85rKrD0EdvyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = \"adam\", loss = \"binarycrossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "#including checkpoints (after each iteration(epoch) -- save progress so that it doesnt have to be executed everytime)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"model_checkpt.h5\", save_best_only = True, verbose = 1)\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience = 2),                   #if after 2 epochs the accuracy does not improve, it will not go further\n",
        "    tf.keras.callbacks.TensorBoard(log_dir = \"logs\")\n",
        "]"
      ],
      "metadata": {
        "id": "SXSNwHABd49-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(x_train, y_train, validation_split = 0.1, batch_size = 16, epochs = 10, callbacks = callbacks)"
      ],
      "metadata": {
        "id": "khMj9cb2fke8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"model training plot\")\n",
        "plt.plot(results.history['accuracy'], label = \"Train Accuracy\")\n",
        "plt.plot(results.history['val_accuracy'], label = \"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iO6C9sfjgn5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"model loss plot\")\n",
        "plt.plot(results.history['loss'], label = \"Train Loss\")\n",
        "plt.plot(results.history['val_loss'], label = \"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b_cvtVJihMGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test model\n",
        "y_pred_mask = model.predict(x_test)\n",
        "imshow(x_test[0])\n",
        "imshow(y_pred_mask[0])\n"
      ],
      "metadata": {
        "id": "PRPW82cThUI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"unet_model.h5\")"
      ],
      "metadata": {
        "id": "dUIQ2khajT4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the model when reopening\n",
        "#make a new file\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "modelll = load_model(\"unet_model.hf\")\n",
        "\n",
        "img = \"imgpath copy paste\"\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "\n",
        "img_width = 128\n",
        "img_height = 128\n",
        "img_channels = 3\n",
        "x_test = np.zeros((1,img_height, img_width, img_channels), dtype = np.unit8)\n",
        "x_test[0] = img\n",
        "\n",
        "img = imread(img)[:,:,:img_channels]\n",
        "img = resize(img, (img_height, img_width), mode = \"constant\", preserve_range = True)\n",
        "\n",
        "pred_mask = model.predict(img)\n",
        "imshow(pred_mask.reshape(128,128))\n"
      ],
      "metadata": {
        "id": "J5WUrFHhjky6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}